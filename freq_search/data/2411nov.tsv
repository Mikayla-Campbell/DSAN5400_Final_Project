Foundation models (FMs) adapt surprisingly well to downstream tasks with fine-tuning. However, their colossal parameter space prohibits their training on resource-constrained edge-devices. For federated fine-tuning, we need to consider the smaller FMs of few billion parameters at most, namely on-device FMs (ODFMs), which can be deployed on-device. Federated fine-tuning of ODFMs has unique challenges non-present in standard fine-tuning: i) ODFMs poorly generalize to downstream tasks due to their limited sizes making proper fine-tuning imperative to their performance, and ii) devices have limited and heterogeneous system capabilities and data that can deter the performance of fine-tuning.Tackling these challenges, we propose HetLoRA, a feasible and effective federated fine-tuning method for ODFMs that leverages the system and data heterogeneity at the edge. HetLoRA allows heterogeneous LoRA ranks across clients for their individual system resources, and efficiently aggregates and distributes these LoRA modules in a data-aware manner by applying rank self-pruning locally and sparsity-weighted aggregation at the server. It combines the advantages of high and low-rank LoRAs, achieving improved convergence speed and final performance compared to homogeneous LoRA. Furthermore, HetLoRA has enhanced computation and communication efficiency compared to full fine-tuning making it more feasible for the edge.
Although accuracy and computation benchmarks are widely available to help choose among neural network models, these are usually trained on datasets with many classes, and do not give a good idea of performance for few (<10) classes. The conventional procedure to predict performance involves repeated training and testing on the different models and dataset variations. We propose an efficient cosine similarity-based classification difficulty measure S that is calculated from the number of classes and intra- and inter-class similarity metrics of the dataset. After a single stage of training and testing per model family, relative performance for different datasets and models of the same family can be predicted by comparing difficulty measures – without further training and testing. Our proposed method is verified by extensive experiments on 8 CNN and ViT models and 7 datasets. Results show that S is highly correlated to model accuracy with correlation coefficient r=0.796, outperforming the baseline Euclidean distance at r=0.66. We show how a practitioner can use this measure to help select an efficient model 6 to 29x faster than through repeated training and testing. We also describe using the measure for an industrial application in which options are identified to select a model 42% smaller than the baseline YOLOv5-nano model, and if class merging from 3 to 2 classes meets requirements, 85% smaller.
Common random string model is a popular model in classi- cal cryptography. We study a quantum analogue of this model called the common Haar state (CHS) model. In this model, every party participating in the cryptographic system receives many copies of one or more i.i.d Haar random states. We study feasibility and limitations of cryptographic primitives in this model and its variants: – We present a construction of pseudorandom function-like states with security against computationally unbounded adversaries, as long as the adversaries only receive (a priori) bounded number of copies. By suitably instantiating the CHS model, we obtain a new approach to construct pseudorandom function-like states in the plain model. – We present separations between pseudorandom function-like states (with super-logarithmic length) and quantum cryptographic primitives, such as interactive key agreement and bit commitment, with classical communication. To show these separations, we prove new results on the indistinguishability of identical versus independent Haar states against LOCC (local operations, classical communication) adversaries.
Cloud systems are integral for delivering scalable and virtualized resources globally. It also provides security updates and monitoring to keep user data safe. However, the growing complexity of these systems poses significant challenges, particularly in the realm of logging and security. It is difficult to know for users which detail is critical for further security analysis of the resources. Also, external packages used in the cloud system require updates by users to mitigate the vulnerability, but the large number of packages to manage makes them outdated versions. This paper shares the weakness of cloud logging systems we observed, which can be exploited by attackers. We propose a tool that configures alerts automatically when commands that have missing details in logs are executed and updates vulnerable versions of packages. Our tool leverages a list that includes the commands with missing details in logs and packages that need to be updated because of the known vulnerabilities. To make the list, we conduct complete enumerating for 1,279 commands in five major resources of Azure to find logs with missing details and search related communities to find vulnerable packages that require the manual update. We evaluate the proposed tool with eight attack scenarios based on real-world cases and the result shows that our tool prevents them successfully.
Femtosecond spectroscopy of FeSe film shows distinct transient nematic behavior below and above superconducting critical temperature. Results reveal correlations between photoinduced nematicity, quasiparticle formation, superconducting and pseudogap openings, emphasizing electronic correlations and preformed electron pairing.
In this paper, we analyze the performances of iterative decoders for linear block codes. In particular, we consider two modifications of the gradient-descent bit flipping (GDBF) algorithm with momentum, where multiple component decoders with different momentum values are concatenated to improve the decoder performance. The learning parameters of the component decoders are obtained by using a Genetic algorithm based on the database of the uncorrectable error patterns of the previous decoder. We present three optimization strategies and provide a comparison with the state-of-the-art decoders. The numerical results are presented on short Bose-Chaudhuri-Hocquenghem (BCH) codes and the channel with additive white Gaussian noise (AWGN).
For the public, understanding Large Language Models (LLMs) can be likened to recognizing how a well-trained assistant works—one that has read an extensive library of information on virtually every topic imaginable. Imagine an assistant that not only reads and remembers all this information but also learns the nuances of how words and ideas are connected across different contexts. This assistant can then use this knowledge to write articles, answer questions, compose emails, or even generate creative stories, all in a manner that feels surprisingly human. This capability comes from what's known as "transformer architecture," a type of design that helps the model pay attention to different parts of the text as it reads, making it adept at understanding and generating language. LLMs are a breakthrough in technology because they can understand and produce language with a level of subtlety and complexity that was previously unachievable, making them valuable tools across various industries. The paper aims to provide a comprehensive analysis of the transformative impact of LLMs across various enterprise sectors. It intends to contribute to the understanding of how LLMs can enhance efficiency, innovation, and decision-making processes in industries such as healthcare, finance, education, and in the software engineering sector. It also provides a comprehensive overview of current popular LLMs in Enterprise applications, in various domains, and discusses the Ethical, Technical, and Regulatory challenges, future trends, and developments in this dynamic field.
In this study, we investigate the fundamental limits of secret-key generation with physical identifiers for compound authentication channels. Our contributions in this paper are the derivations of inner and outer bounds on the optimal tradeoff of secret-key, storage, and privacy-leakage rates for general discrete sources, and we show that these bounds are tight for Gaussian sources. In special cases, our characterizations reduce to existing results derived in previous works.
The remarkable performance of large language models (LLMs) in generation tasks has enabled practitioners to leverage publicly available models to power custom applications, such as chatbots and virtual assistants. However, the data used to train or fine-tune these LLMs is often undisclosed, allowing an attacker to compromise the data and inject backdoors into the models. In this paper, we develop a novel inference time defense, named CLEANGEN, to mitigate backdoor attacks for generation tasks in LLMs. CLEANGEN is a lightweight and effective decoding strategy that is compatible with the state-of-the-art (SOTA) LLMs. Our insight behind CLEANGEN is that compared to other LLMs, back doored LLMs assign significantly higher probabilities to tokens representing the attacker-desired contents. These discrepancies in token probabilities enable CLEANGEN to identify suspicious tokens favored by the attacker and replace them with tokens generated by another LLM that is not compromised by the same attacker, thereby avoiding generation of attacker-desired content. We evaluate CLEANGEN against five SOTA backdoor attacks. Our results show that CLEANGEN achieves lower attack success rates (ASR) compared to five SOTA baseline defenses for all five backdoor attacks. Moreover, LLMs deploying CLEANGEN maintain helpfulness in their responses when serving benign user queries with minimal added computational overhead.
To support positive, ethical human-robot interactions, robots need to be able to respond to unexpected situations in which societal norms are violated, including rejecting unethical commands. Implementing robust communication for robots is inherently difficult due to the variability of context in real-world settings and the risks of unintended influence during robots’ communication. HRI researchers have begun exploring the potential use of LLMs as a solution for language-based communication, which will require an in-depth understanding and evaluation of LLM applications in different contexts. In this work, we explore how an existing LLM responds to and reasons about a set of norm-violating requests in HRI contexts. We ask human participants to assess the performance of a hypothetical GPT-4-based robot on moral reasoning and explanatory language selection as it compares to human intuitions. Our findings suggest that while GPT-4 performs well at identifying norm violation requests and suggesting non-compliant responses, its flaws in not matching the linguistic preferences and context sensitivity of humans prevent it from being a comprehensive solution for moral communication between humans and robots. Based on our results, we provide a four-point recommendation for the community in incorporating LLMs into HRI systems.
Secure aggregation is concerned with the task of securely uploading the inputs associated with multiple users to an aggregation server without revealing the user inputs to the server besides the summation of all inputs. It finds broad applications in distributed machine learning paradigms such as federated learning (FL). Motivated by practical hierarchical FL systems which utilize the client-edge-cloud network architecture to improve delay performance, we study the hierarchical secure aggregation (HSA) problem in a 3-layer hierarchical network where a total of UV users are connected to an aggregation server through U relay nodes each being associated with a disjoint subset of V users. Security requires that the server learn nothing beyond the desired sum of the inputs (server security), and each relay learn nothing about the user inputs (relay security) even if they collude with up to T users. We characterize the optimal communication and key rate region by proposing a novel secure aggregation scheme and deriving an information-theoretic converse that matches the achievable scheme. In particular, we show that when T≥(U−1)V, the proposed HSA problem is infeasible. Otherwise when T<(U−1)V, to securely compute 1 bit of the desired sum, each user needs to upload at least 1 bit to its associating relay, each relay needs to upload at least 1 bit to the server, each user needs to hold at least 1 key bit, and all users need to collectively hold at least max{V+T,min{U+T−1,UV−1}} (source) key bits. The characterization of the source key rate is a major contribution of this work.
The secure summation problem is studied with user selection and collusion, where a server may select any U out of K users and compute the sum of the inputs from the selected users without learning any additional information even if the server colludes with any T out of K users. The optimal communication and randomness rate is characterized when either U=2 or T=1, i.e., to securely compute 1 bit of the selected sum, each user needs to send 1 bit to the server, each user needs to hold a key of T+1 bits when U=2 and U/(U−1)-bits when T=1, and all users need to hold key variables of ((T+22)) bits when U=2 and U/(U−1)+U−1 bits when T=1.
The shift to electronic health records (EHRs) has enhanced patient care and research, but data sharing and complex clinical terminology remain challenges. The Fast Healthcare Interoperability Resource (FHIR) addresses interoperability issues, though extracting insights from FHIR data is still difficult. Traditional analytics often miss critical clinical context, and managing FHIR data requires advanced skills that are in short supply. This study presents FHIRViz, a novel analytics tool that integrates FHIR data with a semantic layer via a knowledge graph. It employs a large language model (LLM) system to extract insights and visualize them effectively. A retrieval vector store improves performance by saving successful generations for fine-tuning. FHIRViz translates clinical queries into actionable insights with high accuracy. Results show FHIRViz with GPT-4 achieving 92.62% accuracy, while Gemini 1.5 Pro reaches 89.34%, demonstrating the tool's potential in overcoming healthcare data analytics challenges.
Modern botnets leverage TLS encryption to mask C&C server communications. TLS certificates used by botnets could exhibit subtle characteristics that facilitate detection. In this paper we investigate whether text features from TLS certificates can be represented by open-source and 3rd party vendor LLM text embeddings in a projected vector space, for the purpose of building a classifier to detect botnet certificates. Our method extracts informative features, generating vector representations for effective identification, creating a projected space that can be queried with test certificates via similarity search. Using a balanced dataset consisting of the publicly available SSLBL botnet certificates and TLS certificates used by popular websites, our evaluations show that C-BERT, an open-source model, emerges as the preferred choice within our proposed system rather than a vendor solution. C-BERT achieves a competitive F1 score of 0.994 on unseen test data, 97.9% accuracy on data gathered several months after an initial projected embedding space was created, and maintains performance in a simulated zero-day evaluation against four C&C groups, with an average F1 score of 0.946. Further evaluation on a random sample of 150,000 real-world certificates collected from a full internet scan between Jan 2024 to May 2024 predicts 13 potential botnet certificates, among which one was confirmed to be malicious by VirusTotal. Comparing with the scenario where no such tool exists, we randomly selected 1,300 certificates from these 150,000 certificates and ran them through VirusTotal, and none were confirmed to be malicious. This translates to 100 fold effort reduction in identifying botnet certificates in the wild.
Predicting a patient's length of stay (LOS) or the units they are likely to visit during the course of the stay can be a vital source of information for healthcare administrators towards effective resource planning. However, predicting these parameters can be challenging due to the lack of sufficient information at admission time, and its potential dependence on inherent practices within the hospital. Prior efforts have focused predominantly on predicting LOS, statically at admission and in isolation. In this paper, we propose an adaptive multi-task learning approach to predict a patient's next unit and the expected length (in days) of the remaining stay. Our approach is capable of capturing any latent relationship that may exist between these two variables. Experimental results on a large real-world in-patient database show that our multi-task model outperforms its single-task counterpart and other classical machine learning models. Our study also demonstrates that: a) it is possible to achieve high prediction scores (e.g., mean absolute error of 2.0 days for remaining LOS, and over 80% accuracy for next unit); and b) such high prediction accuracy can be realized early on---in most cases within the first two days of a patient's stay.
Reinforcement learning (RL) algorithms are traditionally evaluated and compared by their learning trends (i.e., average performance) over trials and time. However, the presence of a single learning trend in a curriculum is, in fact, an assumption. To test this assumption, we used the performance of Proximal Policy Optimization (PPO) under five different curricula aimed at learning dynamic in-hand manipulation tasks. The curricula consisted of different combinations of rewards for lifting and rotating a 5g ball with a three-finger hand with the palm facing down. Mining the performance of all 60 individual trials as time series, we find there are learning trends distinct from the average. We conclude researchers should look beyond the average learning trends when evaluating curriculum learning to fully identify, appreciate, and evaluate the progression of autonomous learning of multi-objective tasks.
This paper presents a cybersecurity testing strategy specifically designed for uncrewed aerial vehicles (UAVs) that is both efficient and comprehensive compared to existing testing methods, along with initiating attack methodologies such as, GPS Spoofing and Denial-of-Service (DoS) on a UAV model to test the effectiveness of our cybersecurity framework. UAVs provide several benefits in today's world. But they are susceptible to many different cybersecurity threats. The goal of the paper is to create a cybersecurity framework catered towards UAVs for users to follow. As widely credited and known for covering all major aspects of cybersecurity, we use NIST (National Institute of Science and Technology) as the leading framework and enhanced each of the five core functions of NIST to fit the exact needs of UAV cybersecurity. This was done through the addition of several other elements from different frameworks such as MITRE ATT&CK (Adversarial, Tactics, Techniques, and Common knowledge), ISO/IEC (International Organization for Standardization/ International Electrotechnical Commission) 27001 and CIS (Center for Internet Security). MITRE ATT&CK aims to share a knowledge-based system on how we can approach different tactics and techniques used by adversaries, and how we can mitigate them from occurring in the future. To demonstrate the criticality of a cybersecurity testing strategy, we used an agent-based simulation environment and represented the effects of a cyber-attack on a UAV if safety implementations are manipulated and not secure enough. Representations of a normal UAV operation were given along with additional visuals demonstrating how these attacks can alter the operation of a UAV system’s response times, resulting in an increase in the likelihood of risk and collision.
Legged robots have become capable of performing highly dynamic maneuvers in the past few years. However, agile locomotion in highly constrained environments such as stepping stones is still a challenge. In this paper, we propose a combination of model-based control, search, and learning to design efficient control policies for agile locomotion on stepping stones. In our framework, we use nonlinear model predictive control (NMPC) to generate whole-body motions for a given contact plan. To efficiently search for an optimal contact plan, we propose to use Monte Carlo tree search (MCTS). While the combination of MCTS and NMPC can quickly find a feasible plan for a given environment (a few seconds), it is not yet suitable to be used as a reactive policy. Hence, we generate a dataset for optimal goal-conditioned policy for a given scene and learn it through supervised learning. In particular, we leverage the power of diffusion models in handling multi-modality in the dataset. We test our proposed framework on a scenario where our quadruped robot Solo12 successfully jumps to different goals in a highly constrained environment (video).
In this qualitative study, we ask: (1) How do Burundian girls and women describe their intersecting identities and (2) How do Burundian girls and women make decisions around STEM education and future careers? To answer these questions, we analyzed interviews conducted with eight Burundian families involved in a university-community organization partnership. 
The fashion industry generates significant textile waste, with approximately 15% of fabric discarded during the cut-and-sew process. Pre-consumer textile waste, such as irregular offcuts, poses challenges for recycling due to contaminants like spandex and plastisol. This study introduces a waste-led product development (WLPD) approach aligned with waste-led design (WLD) and cradle-to-cradle (C2C) principles, where waste is considered a raw material. The researchers utilized pre-consumer textile scraps from Lobo Mau, repurposing them through shaped and frame weaving techniques to create a cohesive, zero-waste garment ensemble. Using unravelled yarns from donated sweaters and fabric ribbons cut from offcuts, a halter top and skirt were woven with no resulting cutting waste. The halter incorporated textured wave motifs inspired by twilight seascapes, while the skirt featured fringe accents for added textural variety. This design demonstrates a scalable method to address contamination issues in textile recycling, emphasizing sustainability, aesthetics, and the extended lifecycle of materials.